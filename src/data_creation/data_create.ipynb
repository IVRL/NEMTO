{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "mi.set_variant('cuda_ad_rgb')\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mitsuba import ScalarTransform4f as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"glass_cat\"\n",
    "train_dir = \"../data/{}/train\".format(exp)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "    print(\"The data directory is created!\")\n",
    "\n",
    "img_train_dir = train_dir+\"/image\"\n",
    "if not os.path.exists(img_train_dir):\n",
    "    os.makedirs(img_train_dir)\n",
    "    print(\"The image directory is created!\")\n",
    "\n",
    "mask_train_dir = train_dir+\"/mask\"\n",
    "if not os.path.exists(mask_train_dir):\n",
    "    os.makedirs(mask_train_dir)\n",
    "    print(\"The mask directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../data/{}/test\".format(exp)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    print(\"The data directory is created!\")\n",
    "\n",
    "img_test_dir = test_dir+\"/image\"\n",
    "if not os.path.exists(img_test_dir):\n",
    "    os.makedirs(img_test_dir)\n",
    "    print(\"The image directory is created!\")\n",
    "\n",
    "mask_test_dir = test_dir+\"/mask\"\n",
    "if not os.path.exists(mask_test_dir):\n",
    "    os.makedirs(mask_test_dir)\n",
    "    print(\"The mask directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sensor_even(origin):\n",
    "    # Apply two rotations to convert from spherical coordinates to world 3D coordinates.\n",
    "    origin = origin\n",
    "\n",
    "    return mi.load_dict({\n",
    "        'type': 'perspective',\n",
    "        'fov': 35,\n",
    "        'to_world': T.look_at(\n",
    "            origin=origin,\n",
    "            target=[0, 0, 0],\n",
    "            up=[0, 1, 0]\n",
    "        ),\n",
    "        'sampler': {\n",
    "            'type': 'independent',\n",
    "            'sample_count': 256\n",
    "        },\n",
    "        'film': {\n",
    "            'type': 'hdrfilm',\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'rfilter': {\n",
    "                'type': 'tent',\n",
    "            },\n",
    "            'pixel_format': 'rgba',\n",
    "        },\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_sphere(samples, rad=2.3):\n",
    "\n",
    "    points = []\n",
    "    phi = math.pi * (3. - math.sqrt(5.))  # golden angle in radians\n",
    "\n",
    "    for i in range(samples):\n",
    "        y = 1 - (i / float(samples - 1)) * 2  # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)  # radius at y\n",
    "\n",
    "        theta = phi * i  # golden angle increment\n",
    "\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "        \n",
    "        p = [x, y, z]\n",
    "\n",
    "        points.append(p/np.linalg.norm(p)*rad)\n",
    "\n",
    "    return points\n",
    "\n",
    "test_sample = 350\n",
    "train_sample = 160\n",
    "\n",
    "origins = fibonacci_sphere(test_sample)[1:201]\n",
    "import random\n",
    "random.shuffle(origins)\n",
    "test_origins = origins[:100]\n",
    "train_origins = origins[100:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sensors = []\n",
    "for origin in train_origins:\n",
    "    train_sensors.append(load_sensor_even(origin))\n",
    "print(\"number of test sensors: \"+str(len(train_sensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sensors = []\n",
    "for origin in test_origins:\n",
    "    test_sensors.append(load_sensor_even(origin))\n",
    "\n",
    "print(\"number of test sensors: \"+str(len(test_sensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change here to for alternative shape and envmap\n",
    "scene_mask = mi.load_dict({\n",
    "    'type': 'scene',\n",
    "    # The keys below correspond to object IDs and can be chosen arbitrarily\n",
    "    'integrator': {'type': 'direct',\n",
    "    'hide_emitters': True,\n",
    "    },\n",
    "    'emitter': {\n",
    "        'type': 'envmap',\n",
    "        'filename': '../scenes/textures/kitchen_morning.exr'},\n",
    "    'kitty': {\n",
    "        'type': 'obj',\n",
    "        'filename': '../scenes/meshes/cat.obj',\n",
    "        'to_world': T.scale([.1, .1, .1]),\n",
    "        'bsdf': {\n",
    "            'type': 'dielectric',\n",
    "            'int_ior': 1.4723,\n",
    "            'ext_ior': 'air'\n",
    "        },\n",
    "    },\n",
    "})\n",
    "\n",
    "ref_train_masks = [mi.render(scene_mask, sensor=sensor) for sensor in train_sensors]\n",
    "ref_test_masks = [mi.render(scene_mask, sensor=sensor) for sensor in test_sensors]\n",
    "print(\"number of train masks \" + str(len(ref_train_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage.exposure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_dig(j):\n",
    "    f = str(j)\n",
    "    if len(f) == 1:\n",
    "        return \"00\"+f\n",
    "    elif len(f) == 2:\n",
    "        return \"0\"+f\n",
    "    else:\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ref_train_masks)):\n",
    "    bmp = mi.Bitmap(ref_train_masks[i])\n",
    "    bmp_np = np.array(bmp)\n",
    "    img_section = bmp_np[:,:,3] > .5\n",
    "    img_section = img_section.astype(np.uint8) * 255\n",
    "\n",
    "    # blur threshold image\n",
    "    blur = cv2.GaussianBlur(img_section, (0,0), sigmaX=1, sigmaY=1, borderType = cv2.BORDER_DEFAULT)\n",
    "    result = skimage.exposure.rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))\n",
    "    # save output\n",
    "    cv2.imwrite(os.path.join(mask_train_dir, \"ref_{}.png\".format(three_dig(i))), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ref_test_masks)):\n",
    "    bmp = mi.Bitmap(ref_test_masks[i])\n",
    "    bmp_np = np.array(bmp)\n",
    "    img_section = bmp_np[:,:,3] > .5\n",
    "    img_section = img_section.astype(np.uint8) * 255\n",
    "\n",
    "    blur = cv2.GaussianBlur(img_section, (0,0), sigmaX=1, sigmaY=1, borderType = cv2.BORDER_DEFAULT)\n",
    "    result = skimage.exposure.rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))\n",
    "    # save output\n",
    "    cv2.imwrite(os.path.join(mask_test_dir, \"ref_{}.png\".format(three_dig(i+100))), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = mi.load_dict({\n",
    "    'type': 'scene',\n",
    "    # The keys below correspond to object IDs and can be chosen arbitrarily\n",
    "    'integrator': {\n",
    "        'type': 'path',\n",
    "        # 'hide_emitters': True,\n",
    "        },\n",
    "    'emitter': {\n",
    "        'type': 'envmap',\n",
    "        'filename': '../scenes/textures/envmap2.exr'},\n",
    "    'kitty': {\n",
    "        'type': 'obj',\n",
    "        'filename': '../scenes/meshes/cat.obj',\n",
    "        'to_world': T.scale([.1, .1, .1]),\n",
    "        'bsdf': {\n",
    "            'type': 'dielectric',\n",
    "            'int_ior': 1.4723,\n",
    "            'ext_ior': 'air'\n",
    "        },\n",
    "    },\n",
    "})\n",
    "\n",
    "ref_train_images = [mi.render(scene, sensor=sensor) for sensor in train_sensors]\n",
    "ref_test_images = [mi.render(scene, sensor=sensor) for sensor in test_sensors]\n",
    "\n",
    "print(\"number of train images \" + str(len(ref_train_images)))\n",
    "print(\"number of test images \" + str(len(ref_test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ref_train_images)):\n",
    "    mi.util.write_bitmap(os.path.join(img_train_dir, \"ref_{}.png\".format(three_dig(i))), ref_train_images[i], write_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ref_test_images)):\n",
    "    mi.util.write_bitmap(os.path.join(img_test_dir, \"ref_{}.png\".format(i+100)), ref_test_images[i], write_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_c2w(cam_desc):\n",
    "    b = str(cam_desc).split('\\n')[23:]\n",
    "    c = np.array(eval((b[0] + b[1] + b[2]+ b[3] + b[4]).replace(\" \", \"\")[9:-1])).flatten()\n",
    "    c[4:12] *= -1\n",
    "    return c.tolist()\n",
    "\n",
    "def cam_intr(cam_desc):\n",
    "    a = str(cam_desc).split('\\n')[1].replace(\" \", \"\")\n",
    "    fov_rad = int(a[7:9])/2 * math.pi / 180\n",
    "    focal_length = 256 / math.tan(fov_rad)\n",
    "    return [focal_length, 0.0, 256.0, 0.0, 0.0, focal_length, 256.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_intrinsic = cam_intr(test_sensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_dict= {}\n",
    "\n",
    "cam_intrinsic = cam_intr(train_sensors[0])\n",
    "\n",
    "for i in range(len(train_sensors)):\n",
    "    k = three_dig(i)\n",
    "    filename = \"ref_{}.exr\".format(k)\n",
    "    cam_i = {}\n",
    "    cam_i[\"K\"] = cam_intrinsic\n",
    "    cam_i[\"C2W\"] = take_c2w(train_sensors[i])\n",
    "    cam_i[\"img_size\"] = [\n",
    "      512,\n",
    "      512\n",
    "    ]\n",
    "    camera_dict[filename] = cam_i\n",
    "\n",
    "\n",
    "with open(os.path.join(train_dir, 'cam_dict_norm.json'), 'w') as outfile:\n",
    "    json.dump(camera_dict, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_test_dict= {}\n",
    "\n",
    "for i in range(len(test_sensors)):\n",
    "    k = three_dig(i+100)\n",
    "    filename = \"ref_{}.exr\".format(k)\n",
    "    cam_i = {}\n",
    "    cam_i[\"K\"] = cam_intrinsic\n",
    "    cam_i[\"C2W\"] = take_c2w(test_sensors[i])\n",
    "    cam_i[\"img_size\"] = [\n",
    "      512,\n",
    "      512\n",
    "    ]\n",
    "    camera_test_dict[filename] = cam_i\n",
    "\n",
    "\n",
    "with open(os.path.join(test_dir, 'cam_dict_norm.json'), 'w') as outfile:\n",
    "    json.dump(camera_test_dict, outfile, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7d34b27658a0161ff1cec83f0cc6a5696fa04ed3bad14adb3ecbea8707cd7a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
